import os
import re
import time
import requests
from requests.exceptions import ConnectionError

CHECKED_PROXY = 'unchecked_proxy_spysone'
url = 'http://spys.one/en/socks-proxy-list/'

xpp = '5'
xf1 = '4'
xf2 = '0'
xf4 = '0'
xf5 = '2'

unchecked = []
file_path_unchecked = '{0}/{1}.txt'.format(os.getcwd(), CHECKED_PROXY)

def get_index(xpp, xf1, xf2, xf4, xf5):
    header = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/12.0.2 Safari/605.1.15'
    }
    data = {
        'xpp': xpp,
        'xf1': xf1,
        'xf2': xf2,
        'xf4': xf4,
        'xf5': xf5
    }
    print('Getting the website...')
    try:
        rsp = requests.post(url=url, headers=header, data=data)
        if rsp.status_code == 200:
            print('Success.')
            html = rsp.text
            return html
        else:
            exit('Can not get the website.')
    except ConnectionError:
        exit('Please run your proxy app and try again.')

def get_proxy_info(html):
    pattern = re.compile(
        r'onmouseout.*?spy14>(.*?)<s.*?write.*?nt>\"\+(.*?)\)</scr.*?/en/(.*?)-', re.S
    )
    infos = re.findall(pattern, html)
    return infos

def parse_proxy_info(html, infos):
    print('å…±è·å–åˆ° {} ä¸ªä»£ç†ã€‚'.format(len(infos)))
    print('å¼€å§‹è§£æä»£ç†è¯¦ç»†ä¿¡æ¯...')
    # æå–ç«¯å£åŠ å¯†ä¸²
    port_word = re.findall(r'\+\(([a-z0-9^]+)\)+', html)

    port_passwd = {}
    # æå–ç«¯å£è§£å¯†è„šæœ¬
    portcode = re.findall(
        r'table><script type="text/javascript">(.*)</script>', html
    )[0].split(';')
    print(f"[è°ƒè¯•] ç«¯å£è§£å¯†è„šæœ¬ç‰‡æ®µæ•°é‡: {len(portcode)}")
    for i in portcode:
        ii = re.findall(r'\w+=\d+', i)
        for i in ii:
            kv = i.split('=')
            if len(kv[1]) == 1:
                k = kv[0]
                v = kv[1]
                port_passwd[k] = v
    print(f"[è°ƒè¯•] ç«¯å£è§£å¯†æ˜ å°„: {port_passwd}")

    for idx, i in enumerate(infos):
        proxies_info = {
            'ip': i[0],
            'port': i[1],
            'protocol': i[2]
        }
        # è§£å¯†ç«¯å£
        port_word = re.findall(r'\((\w+)\^', proxies_info.get('port'))
        port_digital = ''
        for k in port_word:
            port_digital += port_passwd.get(k, '?')
        if '?' in port_digital:
            print(f"[è­¦å‘Š] ç¬¬{idx+1}ä¸ªä»£ç†ç«¯å£è§£å¯†å¤±è´¥: {proxies_info.get('ip')} {proxies_info.get('port')}")
        else:
            print(f"[è°ƒè¯•] ä»£ç†{idx+1}: {proxies_info.get('ip')}:{port_digital} åè®®: {proxies_info.get('protocol')}")
        test_it = '{0}:{1}'.format(proxies_info.get('ip'), port_digital)
        unchecked.append(test_it)

def test_proxies_from_file(file_path, test_url="http://httpbin.org/ip", timeout=5):
    """
    ä»æ–‡ä»¶ä¸­è¯»å–ä»£ç†åˆ—è¡¨ï¼Œé€ä¸ªæ£€æµ‹å…¶å¯ç”¨æ€§ï¼Œå¹¶è¾“å‡ºæ£€æµ‹ç»“æœã€‚
    :param file_path: ä»£ç†åˆ—è¡¨æ–‡ä»¶è·¯å¾„
    :param test_url: ç”¨äºæµ‹è¯•ä»£ç†å¯ç”¨æ€§çš„ç›®æ ‡ç½‘å€
    :param timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    :return: listï¼Œå¯ç”¨ä»£ç†åˆ—è¡¨ï¼ˆæ ¼å¼åŒæ–‡ä»¶ä¸­ï¼Œå¦‚ "ip:port"ï¼‰
    """
    import os
    import requests
    from requests.exceptions import RequestException

    print(f"å¼€å§‹æ£€æµ‹ä»£ç†æ–‡ä»¶: {file_path}")
    if not os.path.exists(file_path):
        print("æœªæ‰¾åˆ°ä»£ç†æ–‡ä»¶ã€‚è¯·å…ˆæŠ“å–ä»£ç†ã€‚")
        return []

    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    proxies = [line.strip() for line in lines if line and not line.startswith('>>>')]
    total = len(proxies)
    available = 0
    available_proxies = []

    print(f"å…±è¯»å–åˆ° {total} ä¸ªä»£ç†ï¼Œå¼€å§‹é€ä¸ªæ£€æµ‹...")

    for i, proxy in enumerate(proxies):
        print(f"æ­£åœ¨æ£€æµ‹ç¬¬ {i+1}/{total} ä¸ªä»£ç†: {proxy}")
        try:
            proxy_url = f"socks5://{proxy}"
            rsp = requests.get(test_url, proxies={"http": proxy_url, "https": proxy_url}, timeout=timeout)
            print(f"ä»£ç† {proxy} æ£€æµ‹ç»“æœ: {rsp.status_code} - {rsp.text.strip()}")
            if rsp.status_code == 200:
                print(f"âœ… å¯ç”¨ä»£ç†: {proxy}")
                available += 1
                available_proxies.append(proxy)
            else:
                print(f"âŒ ä¸å¯ç”¨ä»£ç†: {proxy}ï¼ŒçŠ¶æ€ç : {rsp.status_code}")
        except RequestException as e:
            print(f"âŒ ä¸å¯ç”¨ä»£ç†: {proxy}ï¼Œå¼‚å¸¸ä¿¡æ¯: {e}")

    print(f"\næ£€æµ‹å®Œæˆã€‚å¯ç”¨ä»£ç†æ•°é‡: {available}/{total}")
    return available_proxies

def main():
    html = get_index(xpp, xf1, xf2, xf4, xf5)
    infos = get_proxy_info(html)
    parse_proxy_info(html, infos)
    with open(file_path_unchecked, 'a+', encoding='utf-8') as f:
        f.write(time.strftime(">>>%Y-%m-%d %H:%M:%S", time.localtime()) + '\n')
        for proxy in unchecked:
            f.write(proxy + '\n')
    print('Save to {}.\nDone.'.format(file_path_unchecked))
    return unchecked

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from datetime import datetime

def fetch_product_info(barcode: str, proxy: str = None, headless: bool = True, timeout: int = 10):
    """
    ä½¿ç”¨ Selenium æŠ“å–äº§å“åç§°å’Œå›¾ç‰‡é“¾æ¥ï¼Œå¹¶åœ¨å¤±è´¥æ—¶ä¿å­˜å¸¦æ—¶é—´æˆ³çš„ HTML å’Œæˆªå›¾ã€‚
    """
    base_url = f"https://www.barcodelookup.com/{barcode}"
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")  # å½“å‰æ—¶é—´æˆ³

    image_xpath = '//div[@class="product-image"]//img'
    name_xpath = '//div[@class="product-details"]//h4'

    chrome_options = Options()
    if proxy:
        chrome_options.add_argument(f'--proxy-server={proxy}')
    if headless:
        chrome_options.add_argument('--headless')
    chrome_options.add_argument('--disable-gpu')
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--log-level=3')
    chrome_options.add_argument('--disable-blink-features=AutomationControlled')
    chrome_options.add_argument('--window-size=1920,1080')

    driver = None
    try:
        driver = webdriver.Chrome(options=chrome_options)
        driver.set_page_load_timeout(timeout)

        print(f"ğŸ” æ­£åœ¨è®¿é—®: {base_url}")
        driver.get(base_url)

        wait = WebDriverWait(driver, timeout)
        name_element = wait.until(EC.presence_of_element_located((By.XPATH, name_xpath)))
        image_element = wait.until(EC.presence_of_element_located((By.XPATH, image_xpath)))

        return {
            "barcode": barcode,
            "product_name": name_element.text.strip(),
            "image_url": image_element.get_attribute("src")
        }

    except Exception as e:
        print(f"âŒ æŠ“å–å¤±è´¥: {barcode}ï¼Œé”™è¯¯: {e}")

        # ä¿å­˜æˆªå›¾
        try:
            screenshot_path = f"{barcode}_{timestamp}.png"
            driver.save_screenshot(screenshot_path)
            print(f"ğŸ“¸ å·²ä¿å­˜å¤±è´¥æˆªå›¾: {screenshot_path}")
        except:
            pass

        # ä¿å­˜ HTML
        try:
            html_path = f"{barcode}_{timestamp}.html"
            with open(html_path, "w", encoding="utf-8") as f:
                f.write(driver.page_source)
            print(f"ğŸ’¾ å·²ä¿å­˜ç½‘é¡µ HTML: {html_path}")
        except Exception as html_err:
            print(f"âš ï¸ HTML ä¿å­˜å¤±è´¥: {html_err}")

        return None

    finally:
        if driver:
            driver.quit()


def fetch_barcode_info(barcode: str, proxy_address: str, timeout: int = 10):
    """
    è·å–æ¡å½¢ç ä¿¡æ¯å¹¶ç›´æ¥æ‰“å°çŠ¶æ€ç å’Œç½‘é¡µå†…å®¹ã€‚

    å‚æ•°:
        barcode (str): æ¡å½¢ç ç¼–å·
        proxy_address (str): ä»£ç†åœ°å€ï¼Œæ ¼å¼ä¸º "ip:port"
        timeout (int): è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆé»˜è®¤ 10 ç§’ï¼‰
    """
    url = f"https://www.barcodelookup.com/{barcode}"
    proxy_url = f'socks5h://{proxy_address}'
    proxies = {
        'http': proxy_url,
        'https': proxy_url,
    }

    try:
        response = requests.get(url, proxies=proxies, timeout=timeout)
        print(f"çŠ¶æ€ç : {response.status_code}")
        print("ç½‘é¡µå†…å®¹:\n", response.text)
    except requests.RequestException as e:
        print(f"è¯·æ±‚å¤±è´¥: {e}")

if __name__ == '__main__':
    #main()
    
    a=test_proxies_from_file(file_path_unchecked)
    print(f"å¯ç”¨ä»£ç†æ•°é‡: {len(a)}")
    print("å¯ç”¨ä»£ç†åˆ—è¡¨:")
    for proxy in a:
        print(proxy)
    for proxy in a:
        print(f"ä½¿ç”¨ä»£ç†{proxy}æŠ“å–å•†å“ä¿¡æ¯...")
        #fetch_barcode_info("701666410607", proxy_address=proxy, timeout=10)
        product_info = fetch_product_info("701666410607", proxy=proxy)
        print(f"æŠ“å–ç»“æœ: {product_info}")
